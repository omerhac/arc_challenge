{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arc.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMo+C+FCCAwxCDfg2MqRiAS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omerhac/arc_challenge/blob/master/arc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YShrwCd2GUWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import json\n",
        "from google.cloud import storage\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import colors\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqOKR-POOXki",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-96BlT_hHVkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## get paths\n",
        "GCS_PATH = \"gs://kds-d3cfb3d523ca35d2517017a78110126404d01fdea69417ce49950459\"\n",
        "training_filenames = tf.io.gfile.glob(GCS_PATH + \"/training/*\")\n",
        "test_filenames = tf.io.gfile.glob(GCS_PATH + \"/test/*\")\n",
        "eval_filenames = tf.io.gfile.glob(GCS_PATH + \"/evaluation/*\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yir8C61UKLqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# create datasets with filenames\n",
        "training_dataset = tf.data.Dataset.list_files(training_filenames)\n",
        "eval_dataset = tf.data.Dataset.list_files(eval_filenames)\n",
        "test_dataset = tf.data.Dataset.list_files(test_filenames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTxvSi8tKNSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the jsons\n",
        "def load_task(filename):\n",
        "  task_json = tf.io.read_file(filename)\n",
        "  return task_json\n",
        "\n",
        "training_dataset = training_dataset.map(load_task)\n",
        "eval_dataset = eval_dataset.map(load_task)\n",
        "test_dataset = test_dataset.map(load_task)\n",
        "\n",
        "training_dataset_numpy = tf.data.Dataset.as_numpy_iterator(training_dataset) # convert to numpy iterator\n",
        "eval_dataset_numpy = tf.data.Dataset.as_numpy_iterator(eval_dataset)\n",
        "test_dataset_numpy = tf.data.Dataset.as_numpy_iterator(test_dataset)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBSF4LwyL5G4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "## create a numpy array of tasks (n_tasks, )\n",
        "def array_from_jsons(jsons_numpy_iterator):\n",
        "  \"\"\"\n",
        "    Create an array of task dictionaries from jsons numpy interator\n",
        "  \"\"\"\n",
        "\n",
        "  tasks = []\n",
        "  for task in jsons_numpy_iterator:\n",
        "    tasks.append(json.loads(task))\n",
        "\n",
        "  return np.stack(tasks)\n",
        "\n",
        "## get numpy arrays of datasets\n",
        "training_tasks = array_from_jsons(training_dataset_numpy)\n",
        "eval_tasks = array_from_jsons(eval_dataset_numpy)\n",
        "test_tasks = array_from_jsons(test_dataset_numpy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYLEt0yrPXf9",
        "colab_type": "text"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO9FwJjFNAnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_board(board, ax, title=\"\"):\n",
        "  \"\"\"\n",
        "  Plot a board on a given axis\n",
        "  \"\"\"\n",
        "  cmap = colors.ListedColormap(\n",
        "      ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
        "        '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
        "  norm = colors.Normalize(vmin=0, vmax=9)\n",
        "  \n",
        "  ax.imshow(board, cmap=cmap, norm=norm)\n",
        "  ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n",
        "  ax.set_yticks([x-0.5 for x in range(1+board.shape[0])])\n",
        "  ax.set_xticks([x-0.5 for x in range(1+board.shape[1])])     \n",
        "  ax.set_xticklabels([])\n",
        "  ax.set_yticklabels([])\n",
        "  ax.set_title(title)\n",
        "\n",
        "def plot_one(task, ax, i,train_or_test,input_or_output):\n",
        "  \"\"\"\n",
        "  Plot one task on a given axis\n",
        "  \"\"\"\n",
        "  cmap = colors.ListedColormap(\n",
        "      ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
        "        '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
        "  norm = colors.Normalize(vmin=0, vmax=9)\n",
        "  \n",
        "  input_matrix = task[train_or_test][i][input_or_output]\n",
        "  ax.imshow(input_matrix, cmap=cmap, norm=norm)\n",
        "  ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n",
        "  ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n",
        "  ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n",
        "  ax.set_xticklabels([])\n",
        "  ax.set_yticklabels([])\n",
        "  ax.set_title(train_or_test + ' '+input_or_output)\n",
        "    \n",
        "\n",
        "def plot_task(task):\n",
        "    \"\"\"\n",
        "    Plots the first train and test pairs of a specified task,\n",
        "    using same color scheme as the ARC app\n",
        "    \"\"\"    \n",
        "    num_train = len(task['train'])\n",
        "    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n",
        "    for i in range(num_train):     \n",
        "        plot_one(task, axs[0,i],i,'train','input')\n",
        "        plot_one(task, axs[1,i],i,'train','output')        \n",
        "    plt.tight_layout()\n",
        "    plt.show()        \n",
        "        \n",
        "    num_test = len(task['test'])\n",
        "    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n",
        "    if num_test==1: \n",
        "        plot_one(task, axs[0],0,'test','input')\n",
        "        plot_one(task, axs[1],0,'test','output')     \n",
        "    else:\n",
        "        for i in range(num_test):      \n",
        "            plot_one(axs[0,i],i,'test','input')\n",
        "            plot_one(axs[1,i],i,'test','output')  \n",
        "    plt.tight_layout()\n",
        "    plt.show() \n",
        "  \n",
        "\n",
        "def plot_board_pairs(board_pairs, labels):\n",
        "  \"\"\"\n",
        "  Plots the board pairs with their label as a title\n",
        "  \"\"\"\n",
        "\n",
        "  fig, axs = plt.subplots(len(board_pairs), 2, figsize=(8, 3 * len(board_pairs)))\n",
        "  \n",
        "  for i, pair in enumerate(board_pairs):\n",
        "    # plot a pair on a given axis\n",
        "    plot_board(pair[0], axs[i, 0], title=\"anchor\") \n",
        "    plot_board(pair[1], axs[i, 1], title=labels[i])\n",
        "  \n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlhVzBHEp66s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_task(eval_tasks[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9AnAL0VU2Tu",
        "colab_type": "text"
      },
      "source": [
        "# Check input / output shape distirbution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuTeaiVASRhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset_shapes(dataset):\n",
        "  \"\"\"\n",
        "  Returns dataset board shapes. \n",
        "  \"\"\"\n",
        "\n",
        "  shape_0 = []\n",
        "  shape_1 = []\n",
        "  \n",
        "  # check every task\n",
        "  for task in dataset:\n",
        "    boards = get_task_boards(task) # get all boards\n",
        "    shape_0 += [board.shape[0] for board in boards]\n",
        "    shape_1 += [board.shape[1] for board in boards]\n",
        "  \n",
        "  return shape_0, shape_1\n",
        "\n",
        "def get_task_boards(task, threshold_shape=(np.inf, np.inf), pad=None, test=False):\n",
        "  \"\"\"\n",
        "  Get the training / testing boards of every example in a specific task. \n",
        "\n",
        "  Args: threshold_shape --> threshold shape for which \n",
        "  biggger samples won't be returned. \n",
        "  pad --> functional padding function to pad boards with (up tp threshold_size).\n",
        "  test --> bool, whether a test task or not. for output of task example.\n",
        "  \"\"\"\n",
        "  \n",
        "  boards = []\n",
        "\n",
        "  # train boards\n",
        "  for example in task['train']:\n",
        "    input_board = np.array(example['input'])\n",
        "    output_board = np.array(example['output'])\n",
        "\n",
        "    if((input_board.shape[0] < threshold_shape[0]) and (input_board.shape[1] < threshold_shape[1])):\n",
        "      boards.append(pad(input_board, output_shape=threshold_shape) if pad else input_board) # check for padding func\n",
        "\n",
        "    if((output_board.shape[0] < threshold_shape[0]) and (output_board.shape[1] < threshold_shape[1])):\n",
        "      boards.append(pad(output_board, output_shape=threshold_shape) if pad else output_board) # check for padding func\n",
        "\n",
        "  # test boards\n",
        "  for example in task['test']:\n",
        "    input_board = np.array(example['input'])\n",
        "\n",
        "    if not test: # check if test example\n",
        "      output_board = np.array(example['output'])\n",
        "    \n",
        "    # check whether the board is smaller then threshold shape\n",
        "    if((input_board.shape[0] < threshold_shape[0]) and (input_board.shape[1] < threshold_shape[1])):\n",
        "      boards.append(pad(input_board, output_shape=threshold_shape) if pad else input_board) # check for padding func\n",
        "\n",
        "    if((output_board.shape[0] < threshold_shape[0]) and (output_board.shape[1] < threshold_shape[1]) and (not test)):\n",
        "      boards.append(pad(output_board, output_shape=threshold_shape) if pad else output_board) # check for padding func\n",
        "\n",
        "  return boards\n",
        "\n",
        "def pad(mat, output_shape, padder=0):\n",
        "  \"\"\"\n",
        "  Pad a matrix with padder up to output_shape. Insert matrix at upper left corner.\n",
        "  \n",
        "  Args:\n",
        "  mat - np.array matrix of rank 2\n",
        "  output_shape - tuple \n",
        "  padder - int\n",
        "  \"\"\"\n",
        "\n",
        "  output_board = np.zeros(shape=output_shape) + padder # create output board and pad it\n",
        "\n",
        "  # get input shape\n",
        "  input_rows = mat.shape[0]\n",
        "  input_cols = mat.shape[1]\n",
        "\n",
        "  # if random=False, insert input matrix in upper left corner\n",
        "  output_board[:input_rows, :input_cols] = mat\n",
        "  return output_board\n",
        "\n",
        "def random_pad(mat, output_shape, padder=0):\n",
        "  \"\"\"\n",
        "  Pad a matrix with padder up to output_shape. Insert the matrix at a random location\n",
        "  \n",
        "  Args:\n",
        "  mat - np.array matrix of rank 2\n",
        "  output_shape - tuple \n",
        "  padder - int\n",
        "  seed - int\n",
        "  \"\"\"\n",
        "\n",
        "  output_board = np.zeros(shape=output_shape) + padder # create output board and pad it\n",
        "\n",
        "  # get input shape\n",
        "  input_rows = mat.shape[0]\n",
        "  input_cols = mat.shape[1]\n",
        "\n",
        "  # insert mat at a random loacation\n",
        "  # get random location\n",
        "  start_row = np.random.randint(output_shape[0] - input_rows)\n",
        "  start_col = np.random.randint(output_shape[1] - input_cols)\n",
        "  # insert\n",
        "  output_board[start_row:start_row+input_rows, start_col:start_col+input_cols] = mat\n",
        "\n",
        "  return output_board"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y68hEi25MF8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_shape_0, train_shape_1 = get_dataset_shapes(training_tasks)\n",
        "eval_shape_0, eval_shape_1 = get_dataset_shapes(eval_tasks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP5xNkZ6TSZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## plot\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.subplot(3,2,1)\n",
        "plt.hist(train_shape_0, bins=30)\n",
        "plt.title(\"train shape 0\")\n",
        "plt.subplot(3,2,2)\n",
        "plt.hist(train_shape_1, bins=30)\n",
        "plt.title(\"train shape 1\")\n",
        "plt.subplot(3,2,3)\n",
        "plt.hist(eval_shape_0, bins=30)\n",
        "plt.title(\"eval shape 0\")\n",
        "plt.subplot(3,2,4)\n",
        "plt.hist(eval_shape_1, bins=30)\n",
        "plt.title(\"eval shape 1\")\n",
        "plt.subplot(3,2,5)\n",
        "plt.hist(eval_shape_0 + train_shape_0, bins=30)\n",
        "plt.title(\"combined shape 0\")\n",
        "plt.subplot(3,2,6)\n",
        "plt.hist(eval_shape_1 + train_shape_1, bins=30)\n",
        "plt.title(\"combined shape 1\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugQRmwlhQ8ww",
        "colab_type": "text"
      },
      "source": [
        "## Prepare data for learning pattern features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d70gx45TuZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BOARD_SIZE = (15,15) # board upperbound size\n",
        "\n",
        "# get all boards\n",
        "training_boards = []\n",
        "for task in training_tasks:\n",
        "  training_boards += get_task_boards(task,threshold_shape=BOARD_SIZE, pad=pad)\n",
        "\n",
        "eval_boards = []\n",
        "for task in eval_tasks:\n",
        "  eval_boards += get_task_boards(task,threshold_shape=BOARD_SIZE, pad=pad)\n",
        "\n",
        "test_boards = []\n",
        "for task in test_tasks:\n",
        "  test_boards += get_task_boards(task,threshold_shape=BOARD_SIZE, pad=pad, test=True)\n",
        "\n",
        "all_boards = training_boards+eval_boards+test_boards"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9R2RcE7ZC5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(1,1)\n",
        "plot_board(test_boards[6], ax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLXZsdbYodKl",
        "colab_type": "text"
      },
      "source": [
        "## Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oofkpiCmt8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rotated_views(board):\n",
        "  \"\"\"\n",
        "  Turns a board 90 deg counter clockwise 3 times. Returns a list length 4 with all the rotated views including the original one.\n",
        "  \"\"\"\n",
        "\n",
        "  rotates = [board]\n",
        "  for i in range(3):\n",
        "    board = np.rot90(board)\n",
        "    rotates.append(board)\n",
        "  \n",
        "  return rotates\n",
        "\n",
        "def get_rotated_data_pairs(rotated_views):\n",
        "  \"\"\"\n",
        "  Creates all the possible pairs out of the rotated views tensor and labels them. If a1..a4 are rotated vies (A.C.W) of a1, returns labels according to:\n",
        "   - (a1, a1) = 1 --> same board\n",
        "   - (a1, a2) = 2 --> 90 a.c.w rotate\n",
        "   - (a1, a3) = 3 --> 180 rotate\n",
        "   - (a1, a4) = 4 --> 270 a.c.w rotate\n",
        "   - ...\n",
        "   - (a3, a4) = 2 --> 90 a.c.w rotate\n",
        "\n",
        "  Args:\n",
        "  rotated_views = a list of 4 rotated views of the board\n",
        "\n",
        "  Returns:\n",
        "  pairs: a list of tuples of boards\n",
        "  labels: a list of labels matching each pair\n",
        "  \"\"\"\n",
        "\n",
        "  # stopping rule\n",
        "  if rotated_views == []:\n",
        "    return [], []\n",
        "\n",
        "  anchor = rotated_views[0]  # select board to compare with \n",
        "  pairs, labels = [], []\n",
        "  label = 1 # init label\n",
        "\n",
        "  # iterate over all remaining examples\n",
        "  for view in rotated_views:\n",
        "    pairs.append((anchor, view))\n",
        "    labels.append(label)\n",
        "    label += 1 # update label, views rotate a.c.w\n",
        "  \n",
        "  next_pairs, next_labels = get_rotated_data_pairs(rotated_views[1:]) # recursive call\n",
        "\n",
        "  return pairs + next_pairs, labels + next_labels\n",
        "\n",
        "def get_binary_board(board):\n",
        "  \"\"\"\n",
        "  Returns a binary board. Every non 0 value becomes 1. 0 stays 0.\n",
        "  \"\"\"\n",
        "\n",
        "  return board != 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UX3_CSM55gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test it\n",
        "r = get_rotated_views(test_boards[7])\n",
        "pairs, labels = get_rotated_data_pairs(r)\n",
        "plot_board_pairs(pairs, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gHJfVQ69rDn",
        "colab_type": "text"
      },
      "source": [
        "# Siamese networks architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISOAGouf9ym1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, Lambda, Dense, Flatten, MaxPool2D, Input\n",
        "\n",
        "def get_siamese_networks_model(input_shape):\n",
        "  \"\"\"\n",
        "  Creates siamese networks model. ref paper: https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf\n",
        "  \"\"\"\n",
        "\n",
        "  # define input vectors\n",
        "  input1 = Input(input_shape)\n",
        "  input2 = Input(input_shape)\n",
        "\n",
        "  # define model\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # stack layers\n",
        "  model.add(Conv2D(16, kernel_size=(3,3), activation='relu', input_shape=input_shape, padding='same'))\n",
        "  model.add(Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "  model.add(MaxPool2D(pool_size=(2,2)))\n",
        "  model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "  model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "  model.add(MaxPool2D(pool_size=(2,2)))\n",
        "  model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "\n",
        "  # flatten\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # dense\n",
        "  model.add(Dense(512, activation='sigmoid'))\n",
        "\n",
        "  # compute the two feature vectors\n",
        "  v1 = model(input1)\n",
        "  v2 = model(input2)\n",
        "\n",
        "  # compute L1 loss\n",
        "  L1_Layer = Lambda(lambda tensors: tf.math.abs(tensors[0] - tensors[1]))\n",
        "  L1_diff = L1_Layer([v1, v2])\n",
        "\n",
        "  # compute probs\n",
        "  probs = Dense(5, activation='softmax')(L1_diff)\n",
        "\n",
        "  siamese_net = tf.keras.Model(inputs=[input1, input2], outputs=probs)\n",
        "  siamese_net.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
        "  return siamese_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ub0eA9dQMJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sn = get_siamese_networks_model([*BOARD_SIZE, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJiUNlKTQQnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sn.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuiwL8exQ5A8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(sn, to_file='model.png', show_shapes=True, expand_nested=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnKVXvD8TmZu",
        "colab_type": "text"
      },
      "source": [
        "# Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibYTel0ORlJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_pairs(board, all_boards):\n",
        "  \"\"\"\n",
        "  Creates a list of pairs of data for the board. For all the possible rotates and a false match\n",
        "\n",
        "  Args:\n",
        "  board - np.array\n",
        "  all_boards - all the other boards on the dataset not including this one\n",
        "\n",
        "  Returns:\n",
        "  a list of 5 tuples, 4 for the rotation part and 1 for a false match\n",
        "  \"\"\"\n",
        "\n",
        "  rotated_views = get_rotated_views(board)\n",
        "  rotated_pairs, rotated_labels = get_rotated_data_pairs(rotated_views)\n",
        "\n",
        "  # create false match pair\n",
        "  different_board = all_boards[np.random.randint(len(all_boards))] # generate random example\n",
        "  false_label = 0\n",
        "\n",
        "  return rotated_pairs + [(board, different_board)], rotated_labels + [false_label]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZA3unNtUSBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a list of all boards augmentation data\n",
        "pair_list = []\n",
        "label_list = []\n",
        "\n",
        "# iterate over all boards\n",
        "for i, board in enumerate(all_boards):\n",
        "  board_pairs, board_labels = get_all_pairs(board, all_boards[i:]) # augment example. use only boards from here onward\n",
        "  pair_list += board_pairs\n",
        "  label_list += board_labels\n",
        "\n",
        "# zip to a single dataset\n",
        "board_list_dataset = list(zip(pair_list, label_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IrvJa5Ga3m5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "## create tf dataset\n",
        "boards_dataset = tf.data.Dataset.from_tensor_slices(board_list_dataset)\n",
        "boards_dataset = boards_dataset.Shuffle(2048)\n",
        "boards_dataset = boards_dataset.Batch(BATCH_SIZE)\n",
        "boards_dataset = boards_dataset.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfvNty6FbxNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for board in boards_dataset:\n",
        "  print(board)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}