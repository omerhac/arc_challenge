{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "board_gan.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPoWUWdvDNgfAHHtuyq2j92",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omerhac/arc_challenge/blob/master/board_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlv1GB4-Nyzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbftZ2NoObBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "6f332d86-0d73-4194-c323-f1a0ee2cf750"
      },
      "source": [
        "!pip install import_ipynb\n",
        "import import_ipynb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting import_ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=2b58ee4afbc3ec87cd3b551a69ac563888cfeded9eb787160c02786d9964974d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHJh_xVxOpYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "b3afa29c-06ba-4019-cc6f-839276d93c1d"
      },
      "source": [
        "# get repository from github\n",
        "!git clone https://github.com/omerhac/arc_challenge.git\n",
        "\n",
        "# navigate to dir\n",
        "%cd arc_challenge"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'arc_challenge'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 194 (delta 6), reused 0 (delta 0), pack-reused 179\u001b[K\n",
            "Receiving objects: 100% (194/194), 10.54 MiB | 5.93 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n",
            "/content/arc_challenge\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXkWlMCKO5QY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb02b398-8f98-41ac-c27e-6f938bab2b99"
      },
      "source": [
        "import preprocess"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from preprocess.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-kSWbocP3xG",
        "colab_type": "text"
      },
      "source": [
        "# Data loading and gathering\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Je068QPnsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the lists of tasks\n",
        "training_tasks, eval_tasks, test_tasks = preprocess.load_data_from_jsons()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFw86YhoP688",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augment and arrange the data as an array\n",
        "all_boards = preprocess.get_all_boards(training_tasks, eval_tasks, test_tasks)\n",
        "all_boards += preprocess.get_all_boards(training_tasks, eval_tasks, test_tasks) # add another batch of randomly padd boards\n",
        "\n",
        "# make all boards binary\n",
        "all_boards = [preprocess.model_shape_board(preprocess.get_binary_board(board)) for board in all_boards]\n",
        "\n",
        "# get rotated views of all the boards\n",
        "rotated_boards = []\n",
        "\n",
        "for board in all_boards:\n",
        "  rotated_views = preprocess.get_rotated_views(board)\n",
        "  rotated_boards += rotated_views\n",
        "\n",
        "# stack\n",
        "rotated_boards = np.stack(rotated_boards)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7PyfjX7TRB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ffb85cd0-77e3-4db6-b47c-c3ec9f45640d"
      },
      "source": [
        "print(rotated_boards.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(136320, 16, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tCJHyZYW0Hh",
        "colab_type": "text"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELqCBMY3FulS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## constants \"\" \n",
        "GENERATOR_DENSE_REP = 50\n",
        "N_CHANNELS = 1\n",
        "BOARD_SIZE = [16,16]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J33SGSwCDYWb",
        "colab_type": "text"
      },
      "source": [
        "# Defining the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz1IdwGxWtfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Conv2DTranspose, BatchNormalization, Input\n",
        "def generator():\n",
        "  \"\"\"\n",
        "  Creates a board generator\n",
        "  \"\"\"\n",
        "\n",
        "  def util_gen(z):\n",
        "    \"\"\"\n",
        "    A utility generator function to be used in a lambda later on\n",
        "    \"\"\"\n",
        "\n",
        "    # project and reshape z\n",
        "    linear = Dense(128*4*4, activation='linear')(z)\n",
        "    reshaped_z = tf.keras.layers.Reshape([4, 4, 128])(linear)\n",
        "\n",
        "    # first deconv layer\n",
        "    g_conv1 = Conv2DTranspose(64, kernel_size=(3,3), activation='relu')(reshaped_z)\n",
        "    g_normalized_1 = BatchNormalization(momentum=0.9)(g_conv1)\n",
        "\n",
        "    # second deconv layer\n",
        "    g_conv2 = Conv2DTranspose(32, kernel_size=(3,3), activation='relu')(g_normalized_1)\n",
        "    g_normalized_2 = BatchNormalization(momentum=0.9)(g_conv2)\n",
        "\n",
        "    # third deconv layer\n",
        "    g_conv3 = Conv2DTranspose(32, kernel_size=(3,3), activation='relu')(g_normalized_2)\n",
        "    g_normalized_3 = BatchNormalization(momentum=0.9)(g_conv3)\n",
        "\n",
        "    # fourth deconv layer\n",
        "    g_conv4 = Conv2DTranspose(16, kernel_size=(3,3), activation='relu')(g_normalized_3)\n",
        "    g_normalized_4 = BatchNormalization(momentum=0.9)(g_conv4)\n",
        "\n",
        "    # fifth deconv layer\n",
        "    g_conv5 = Conv2DTranspose(8, kernel_size=(3,3), activation='relu')(g_normalized_4)\n",
        "    g_normalized_5 = BatchNormalization(momentum=0.9)(g_conv5)\n",
        "\n",
        "    # final layer\n",
        "    output_board = Conv2DTranspose(1, kernel_size=(3,3), activation='relu')(g_normalized_5)\n",
        "\n",
        "    return output_board\n",
        "\n",
        "  return lambda z: util_gen(z)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkqNcrgYLXux",
        "colab_type": "text"
      },
      "source": [
        "## Defining discriminator "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQIghRGOLfcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D\n",
        "def discriminator():\n",
        "  \"\"\"\n",
        "  Creates a discriminator\n",
        "  \"\"\"\n",
        "\n",
        "  def util_discriminator(board):\n",
        "    \"\"\"\n",
        "    A utility discriminator to be used in a lambda later on\n",
        "    \"\"\"\n",
        "\n",
        "    # first layer\n",
        "    d_conv1 = Conv2D(8, kernel_size=(3,3), activation='relu', name=\"d_conv1\")(board)\n",
        "    d_normalized_1 = BatchNormalization(momentum=0.9)(d_conv1)\n",
        "\n",
        "    # second layer\n",
        "    d_conv2 = Conv2D(16, kernel_size=(3,3), activation='relu', name=\"d_conv2\")(d_normalized_1)\n",
        "    d_normalized_2 = BatchNormalization(momentum=0.9)(d_conv2)\n",
        "\n",
        "    # third layer\n",
        "    d_conv3 = Conv2D(32, kernel_size=(3,3), activation='relu', name=\"d_conv3\")(d_normalized_2)\n",
        "    d_normalized_3 = BatchNormalization(momentum=0.9)(d_conv3)\n",
        "\n",
        "    # fourth layer\n",
        "    d_conv4 = Conv2D(64, kernel_size=(3,3), activation='relu', name=\"d_conv4\")(d_normalized_3)\n",
        "    d_normalized_4 = BatchNormalization(momentum=0.9)(d_conv4)\n",
        "\n",
        "    # fifth layer\n",
        "    d_conv5 = Conv2D(128, kernel_size=(3,3), activation='relu', name=\"d_conv5\")(d_normalized_4)\n",
        "    d_normalized_5 = BatchNormalization(momentum=0.9)(d_conv5)\n",
        "\n",
        "    # avarage_pooling\n",
        "    d_ap = GlobalAveragePooling2D()(d_normalized_5)\n",
        "\n",
        "    # dense\n",
        "    d_out = Dense(1, activation='sigmoid')(d_ap)\n",
        "\n",
        "    return d_out\n",
        "  \n",
        "  return lambda boards: util_discriminator(boards)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEzqeG4WGHJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_generator():\n",
        "  z = Input([GENERATOR_DENSE_REP], name='z')\n",
        "  output = generator()(z)\n",
        "  \n",
        "  model = tf.keras.Model(inputs=z, outputs=output)\n",
        "  return model\n",
        "\n",
        "def get_discriminator():\n",
        "  boards = Input([*BOARD_SIZE, 1], name='boards')\n",
        "  output = discriminator()(boards)\n",
        "  \n",
        "  model = tf.keras.Model(inputs=boards, outputs=output)\n",
        "  return model"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD1ynmbIiMlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = get_generator()\n",
        "d = get_discriminator()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy9SMPQ8yj2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3308c3fd-32a5-41f6-82d7-23bda060e7f3"
      },
      "source": [
        "print(len(g.trainable_weights))\n",
        "print(g.trainable_weights[2].shape)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24\n",
            "(3, 3, 64, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTa-z_ybftFc",
        "colab_type": "text"
      },
      "source": [
        "# Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV46BI-HJ0KT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as kb\n",
        "\n",
        "def discriminator_loss(d_real, d_fake):\n",
        "  \"\"\" \n",
        "  discrimintor loss function\n",
        "\n",
        "  args:\n",
        "  d_real - decisions on real boards\n",
        "  d_fake - decisions on fake boards\n",
        "  \"\"\"\n",
        "\n",
        "  real_part = kb.log(d_real)\n",
        "  fake_part = kb.log(1-d_fake)\n",
        " \n",
        "  # compute loss\n",
        "  loss = (-1/BATCH_SIZE) * kb.sum(real_part + fake_part)\n",
        "\n",
        "  return loss\n",
        "\n",
        "def generator_loss(d_fake):\n",
        "  \"\"\"\n",
        "  generator loss\n",
        "\n",
        "  args:\n",
        "  d_fake - discriminator decisions on fake images\n",
        "  \"\"\"\n",
        "\n",
        "  loss = (-1/BATCH_SIZE) * kb.sum(kb.log(d_fake))\n",
        "  \n",
        "  return loss"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMj1obu2hF_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 1\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "# get bum of batches\n",
        "num_of_batches = 1#rotated_boards.shape[0] // BATCH_SIZE \n",
        "\n",
        "# initate optimizers\n",
        "g_optimizer = tf.keras.optimizers.Adam()\n",
        "d_optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  for batch_num in range(num_of_batches):\n",
        "    \n",
        "    # open gradient tape\n",
        "    with tf.GradientTape(persistent=True) as tape: # persistent is needed for drawing gradients twice\n",
        "      # GENERATE BOARDS\n",
        "      # generate random dense representations\n",
        "      rand_dense_reps = np.random.uniform(-1, 1, [BATCH_SIZE, GENERATOR_DENSE_REP]).astype(np.float32)\n",
        "\n",
        "      # apply generator\n",
        "      fake_boards = g(rand_dense_reps, training=True)\n",
        "      \n",
        "      # DISCRIMINATE\n",
        "      # batch some real examples\n",
        "      real_boards = rotated_boards[batch_num*BATCH_SIZE:(batch_num+1)*BATCH_SIZE]\n",
        "\n",
        "      d_fake = d(fake_boards, training=True) # decesions on fake boards\n",
        "      d_real = d(real_boards, training=True) # decisions on real boards\n",
        "\n",
        "      # compute losses\n",
        "      g_loss = generator_loss(d_fake) # generator loss\n",
        "      d_loss = discriminator_loss(d_real, d_fake) # discriminator loss \n",
        "\n",
        "    # get gradients\n",
        "    g_grad = tape.gradient(g_loss, g.trainable_weights) # gradient of the generator loss function wrt generator weights\n",
        "    d_grad = tape.gradient(d_loss, d.trainable_weights) # gradient of discriminator loss function wrt discriminator weights\n",
        "    \n",
        "    # TRAIN\n",
        "    g_optimizer.apply_gradients(zip(g_grad, g.trainable_weights))\n",
        "    d_optimizer.apply_gradients(zip(d_grad, d.trainable_weights))\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx3vqYKsi16g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c492ccf8-30e0-48c1-ba86-34bc129ecfb1"
      },
      "source": [
        "b = preprocess.plotting_shape_board(fake_boards[0].numpy())\n",
        "fig, ax = plt.subplots(1,1)\n",
        "preprocess.plot_board(b, ax)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.09085584 0.27208078 0.56420976 0.21294771 0.3276364  0.27918443\n",
            "  0.42929804 0.52898926 0.30244088 0.5328341  0.0802173  0.33635592\n",
            "  0.38025215 0.12041657 0.19872352 0.21351208]\n",
            " [0.         0.13100173 0.56713045 0.8341846  0.8775359  0.64349836\n",
            "  0.24370953 0.41263312 0.97629267 0.         0.43991572 0.84633625\n",
            "  0.8045886  0.30855244 0.1522831  0.        ]\n",
            " [0.         0.         0.         0.60195786 0.         0.\n",
            "  0.214544   0.         0.         0.         0.         0.\n",
            "  0.33545637 0.46381992 0.49561977 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.3157453\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.33335805 1.0788002  0.        ]\n",
            " [0.04258775 0.41171455 0.31721193 0.         0.         0.\n",
            "  0.9412259  1.3510075  0.         0.08266741 0.86685085 0.5074456\n",
            "  0.         0.30789948 0.25355935 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.36046666 1.6778626  0.         1.9390523  0.         0.\n",
            "  1.9765114  0.75148296 0.         0.        ]\n",
            " [0.         0.         0.         0.23063892 0.         0.30397138\n",
            "  0.3304848  1.4468127  1.881485   3.4668386  0.         2.2076135\n",
            "  0.         0.         0.43865013 0.        ]\n",
            " [0.         0.         0.         1.1371906  0.63437647 0.\n",
            "  0.         0.         2.2483747  2.0816088  3.0786815  0.7726671\n",
            "  0.         1.6059937  0.85661554 0.        ]\n",
            " [0.         0.         0.         0.17684822 1.1060498  2.5991151\n",
            "  0.         0.         1.8482671  0.         3.0570362  0.767178\n",
            "  0.         2.403617   0.74183697 0.        ]\n",
            " [0.         0.         0.2661189  0.28810066 0.13876319 3.2864506\n",
            "  5.5028467  0.         1.1104977  3.3418381  2.0950086  0.\n",
            "  0.         2.4778688  0.8586088  0.        ]\n",
            " [0.1507661  0.03788892 0.04816133 0.         1.2652547  1.5399847\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.43429407 2.707331   0.19721368 0.        ]\n",
            " [0.         0.080356   0.         0.         0.99493    0.\n",
            "  0.         2.7461019  0.         0.         0.         0.5171498\n",
            "  0.3158242  1.2962251  0.75369346 0.        ]\n",
            " [0.         0.12864631 0.         0.         0.         0.\n",
            "  0.         0.         0.42072713 0.         0.         0.\n",
            "  0.         1.2422751  0.64969045 0.        ]\n",
            " [0.         0.2498175  0.         0.         0.         0.\n",
            "  0.12762672 0.         0.         0.         0.         0.\n",
            "  0.         0.09643218 0.52314997 0.        ]\n",
            " [0.08474633 0.7338855  0.40371168 0.05674308 0.         0.\n",
            "  0.         0.         0.         0.44300163 0.11457407 0.47290313\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.06932369 0.575025   0.44656166 0.3885166  0.17996068 0.64001083\n",
            "  0.477517   0.09621844 0.42810202 0.05670072 0.68579096 0.7560373\n",
            "  0.2685074  0.26130557 0.         0.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXxYDaUoslzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}