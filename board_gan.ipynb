{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "board_gan.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7KsXmn3dDj6Sa3L/NcC+D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omerhac/arc_challenge/blob/master/board_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlv1GB4-Nyzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbftZ2NoObBE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "7c9498ae-32cc-4461-ae3c-344df00298a2"
      },
      "source": [
        "!pip install import_ipynb\n",
        "import import_ipynb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting import_ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=973332d2acf7d8b3a5980d14ccb1ada2b8d97ef91598193a2109eba79fda5dd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHJh_xVxOpYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "e6177810-8e83-459c-db98-4534fb5b2fbc"
      },
      "source": [
        "# get repository from github\n",
        "!git clone https://github.com/omerhac/arc_challenge.git\n",
        "\n",
        "# navigate to dir\n",
        "%cd arc_challenge"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'arc_challenge'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 197 (delta 8), reused 0 (delta 0), pack-reused 179\u001b[K\n",
            "Receiving objects: 100% (197/197), 10.54 MiB | 11.25 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n",
            "/content/arc_challenge\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXkWlMCKO5QY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0126f4c5-c571-4f42-c454-59a05ee799f9"
      },
      "source": [
        "import preprocess"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "importing Jupyter notebook from preprocess.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-kSWbocP3xG",
        "colab_type": "text"
      },
      "source": [
        "# Data loading and gathering\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Je068QPnsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the lists of tasks\n",
        "training_tasks, eval_tasks, test_tasks = preprocess.load_data_from_jsons()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFw86YhoP688",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# augment and arrange the data as an array\n",
        "all_boards = preprocess.get_all_boards(training_tasks, eval_tasks, test_tasks)\n",
        "all_boards += preprocess.get_all_boards(training_tasks, eval_tasks, test_tasks) # add another batch of randomly padd boards\n",
        "\n",
        "# make all boards binary\n",
        "all_boards = [preprocess.model_shape_board(preprocess.get_binary_board(board)) for board in all_boards]\n",
        "\n",
        "# get rotated views of all the boards\n",
        "rotated_boards = []\n",
        "\n",
        "for board in all_boards:\n",
        "  rotated_views = preprocess.get_rotated_views(board)\n",
        "  rotated_boards += rotated_views\n",
        "\n",
        "# stack\n",
        "rotated_boards = np.stack(rotated_boards)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7PyfjX7TRB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa4725ab-57a7-4b19-f829-1c4635cf91f5"
      },
      "source": [
        "print(rotated_boards.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(136320, 16, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tCJHyZYW0Hh",
        "colab_type": "text"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELqCBMY3FulS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## constants ##\n",
        "GENERATOR_DENSE_REP = 64\n",
        "N_CHANNELS = 1\n",
        "BOARD_SIZE = [16,16]"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J33SGSwCDYWb",
        "colab_type": "text"
      },
      "source": [
        "# Defining the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz1IdwGxWtfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Conv2DTranspose, BatchNormalization, Input\n",
        "def generator():\n",
        "  \"\"\"\n",
        "  Creates a board generator\n",
        "  \"\"\"\n",
        "\n",
        "  def util_gen(z):\n",
        "    \"\"\"\n",
        "    A utility generator function to be used in a lambda later on\n",
        "    \"\"\"\n",
        "\n",
        "    # project and reshape z\n",
        "    linear = Dense(512*2*2, activation='linear')(z)\n",
        "    reshaped_z = tf.keras.layers.Reshape([2, 2, 512])(linear)\n",
        "\n",
        "    # first deconv layer\n",
        "    g_conv1 = Conv2DTranspose(256, kernel_size=(3,3), activation='relu', strides=(2,2), padding='same')(reshaped_z)\n",
        "    g_normalized_1 = BatchNormalization(momentum=0.9)(g_conv1)\n",
        "\n",
        "    # second deconv layer\n",
        "    g_conv2 = Conv2DTranspose(128, kernel_size=(3,3), activation='relu', strides=(2,2), padding='same')(g_normalized_1)\n",
        "    g_normalized_2 = BatchNormalization(momentum=0.9)(g_conv2)\n",
        "    \"\"\"\n",
        "    # third deconv layer\n",
        "    g_conv3 = Conv2DTranspose(32, kernel_size=(3,3), activation='relu', strides=(2,2), padding='same')(g_normalized_2)\n",
        "    g_normalized_3 = BatchNormalization(momentum=0.9)(g_conv3)\n",
        "    \n",
        "    # fourth deconv layer\n",
        "    g_conv4 = Conv2DTranspose(16, kernel_size=(3,3), activation='relu')(g_normalized_3)\n",
        "    g_normalized_4 = BatchNormalization(momentum=0.9)(g_conv4)\n",
        "\n",
        "    # fifth deconv layer\n",
        "    g_conv5 = Conv2DTranspose(8, kernel_size=(3,3), activation='relu')(g_normalized_4)\n",
        "    g_normalized_5 = BatchNormalization(momentum=0.9)(g_conv5)\n",
        "    \"\"\"\n",
        "    # final layer\n",
        "    output_board = Conv2DTranspose(1, kernel_size=(3,3), activation='sigmoid', strides=(2,2), padding='same')(g_normalized_2)\n",
        "\n",
        "    return output_board\n",
        "\n",
        "  return lambda z: util_gen(z)\n"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkqNcrgYLXux",
        "colab_type": "text"
      },
      "source": [
        "## Defining discriminator "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQIghRGOLfcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D\n",
        "def discriminator():\n",
        "  \"\"\"\n",
        "  Creates a discriminator\n",
        "  \"\"\"\n",
        "\n",
        "  def util_discriminator(board):\n",
        "    \"\"\"\n",
        "    A utility discriminator to be used in a lambda later on\n",
        "    \"\"\"\n",
        "\n",
        "    # first layer\n",
        "    d_conv1 = Conv2D(8, kernel_size=(3,3), activation='relu', name=\"d_conv1\")(board)\n",
        "    d_normalized_1 = BatchNormalization(momentum=0.9)(d_conv1)\n",
        "\n",
        "    # second layer\n",
        "    d_conv2 = Conv2D(16, kernel_size=(3,3), activation='relu', name=\"d_conv2\")(d_normalized_1)\n",
        "    d_normalized_2 = BatchNormalization(momentum=0.9)(d_conv2)\n",
        "\n",
        "    # third layer\n",
        "    d_conv3 = Conv2D(32, kernel_size=(3,3), activation='relu', name=\"d_conv3\")(d_normalized_2)\n",
        "    d_normalized_3 = BatchNormalization(momentum=0.9)(d_conv3)\n",
        "\n",
        "    # fourth layer\n",
        "    d_conv4 = Conv2D(64, kernel_size=(3,3), activation='relu', name=\"d_conv4\")(d_normalized_3)\n",
        "    d_normalized_4 = BatchNormalization(momentum=0.9)(d_conv4)\n",
        "\n",
        "    # dense 1\n",
        "    dense1 = Dense(512, activation='relu')(d_normalized_4)\n",
        "\n",
        "    # dense 2\n",
        "    dense2 = Dense(128, activation='relu')(dense1)\n",
        "\n",
        "    # output\n",
        "    d_out = Dense(1, activation='sigmoid')(dense2)\n",
        "\n",
        "    return d_out\n",
        "  \n",
        "  return lambda boards: util_discriminator(boards)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEzqeG4WGHJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_generator():\n",
        "  z = Input([GENERATOR_DENSE_REP], name='z')\n",
        "  output = generator()(z)\n",
        "  \n",
        "  model = tf.keras.Model(inputs=z, outputs=output)\n",
        "  return model\n",
        "\n",
        "def get_discriminator():\n",
        "  boards = Input([*BOARD_SIZE, 1], name='boards')\n",
        "  output = discriminator()(boards)\n",
        "  \n",
        "  model = tf.keras.Model(inputs=boards, outputs=output)\n",
        "  return model"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD1ynmbIiMlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = get_generator()\n",
        "d = get_discriminator()"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTa-z_ybftFc",
        "colab_type": "text"
      },
      "source": [
        "# Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV46BI-HJ0KT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as kb\n",
        "\n",
        "def discriminator_loss(d_real, d_fake):\n",
        "  \"\"\" \n",
        "  discrimintor loss function\n",
        "\n",
        "  args:\n",
        "  d_real - decisions on real boards\n",
        "  d_fake - decisions on fake boards\n",
        "  \"\"\"\n",
        "\n",
        "  real_part = kb.log(d_real)\n",
        "  fake_part = kb.log(1-d_fake)\n",
        " \n",
        "  # compute loss\n",
        "  loss = (-1/BATCH_SIZE) * kb.sum(real_part + fake_part)\n",
        "\n",
        "  return loss\n",
        "\n",
        "def generator_loss(d_fake):\n",
        "  \"\"\"\n",
        "  generator loss\n",
        "\n",
        "  args:\n",
        "  d_fake - discriminator decisions on fake images\n",
        "  \"\"\"\n",
        "\n",
        "  loss = (-1/BATCH_SIZE) * kb.sum(kb.log(d_fake))\n",
        "  \n",
        "  return loss"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMj1obu2hF_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "58856406-a6c2-4149-cb57-b0cf20343aaf"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "EPOCHS = 4\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# get bum of batches\n",
        "num_of_batches = rotated_boards.shape[0] // BATCH_SIZE \n",
        "\n",
        "# initate optimizers\n",
        "g_optimizer = tf.keras.optimizers.Adam()\n",
        "d_optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # for plotting later\n",
        "  batches = []\n",
        "  g_losses, d_losses = [], []\n",
        "\n",
        "  for batch_num in range(num_of_batches):\n",
        "\n",
        "    # open gradient tape\n",
        "    with tf.GradientTape(persistent=True) as tape: # persistent is needed for drawing gradients twice\n",
        "      # GENERATE BOARDS\n",
        "      # generate random dense representations\n",
        "      rand_dense_reps = np.random.uniform(-1, 1, [BATCH_SIZE, GENERATOR_DENSE_REP]).astype(np.float32)\n",
        "\n",
        "      # apply generator\n",
        "      fake_boards = g(rand_dense_reps, training=True)\n",
        "      \n",
        "      # DISCRIMINATE\n",
        "      # batch some real examples\n",
        "      real_boards = rotated_boards[batch_num*BATCH_SIZE:(batch_num+1)*BATCH_SIZE]\n",
        "\n",
        "      d_fake = d(fake_boards, training=True) # decesions on fake boards\n",
        "      d_real = d(real_boards, training=True) # decisions on real boards\n",
        "\n",
        "      # compute losses\n",
        "      g_loss = generator_loss(d_fake) # generator loss\n",
        "      d_loss = discriminator_loss(d_real, d_fake) # discriminator loss \n",
        "\n",
        "    # get gradients\n",
        "    g_grad = tape.gradient(g_loss, g.trainable_weights) # gradient of the generator loss function wrt generator weights\n",
        "    d_grad = tape.gradient(d_loss, d.trainable_weights) # gradient of discriminator loss function wrt discriminator weights\n",
        "    \n",
        "    # TRAIN\n",
        "    g_optimizer.apply_gradients(zip(g_grad, g.trainable_weights))\n",
        "    d_optimizer.apply_gradients(zip(d_grad, d.trainable_weights))\n",
        "\n",
        "    # do some prints\n",
        "    if batch_num % (num_of_batches // 100) == 1:\n",
        "      clear_output(wait=True)\n",
        "      print(\"EPOCH NUM: {}\".format(epoch))\n",
        "      print(\"{} % done\".format(int((batch_num / num_of_batches) * 100))) # batch progress status\n",
        "\n",
        "      # print losses\n",
        "      print(\"generator loss: {}\".format(g_loss.numpy())) \n",
        "      print(\"discriminator loss: {}\".format(d_loss.numpy())) \n",
        "\n",
        "      # collect batches for plotting later:\n",
        "      batches.append(batch_num)\n",
        "\n",
        "      # append losses\n",
        "      g_losses.append(g_loss.numpy())\n",
        "      d_losses.append(d_loss.numpy())\n",
        "\n",
        "      # plot losses\n",
        "      plt.figure(figsize=(7,4))\n",
        "      plt.plot(batches, g_losses, label='g_loss')\n",
        "      plt.plot(batches, d_losses, label='d_loss')\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "\n"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH NUM: 1\n",
            "6 % done\n",
            "generator loss: 465.9611511230469\n",
            "discriminator loss: 0.1186516284942627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-191-ef04f4ec0afb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# get gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mg_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# gradient of the generator loss function wrt generator weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0md_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# gradient of discriminator loss function wrt discriminator weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# TRAIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gradient_tape/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1686\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5537\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5538\u001b[0m   r\"\"\"Multiply the matrix \"a\" by the matrix \"b\".\n\u001b[1;32m   5539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx3vqYKsi16g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "59738030-e8cb-4804-fdac-6c62e4b90a4c"
      },
      "source": [
        "b = preprocess.plotting_shape_board(g(np.random.uniform(-1, 1, [2000, GENERATOR_DENSE_REP]).astype(np.float32)).numpy()[106])\n",
        "fig, ax = plt.subplots(1,1)\n",
        "preprocess.plot_board(b, ax)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXxYDaUoslzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}