{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8z5AKhfNNWOYwS4Ld0wOA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omerhac/arc_challenge/blob/master/preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp_9c6-wB6Up",
        "colab_type": "text"
      },
      "source": [
        "# Data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwpZzu4xIsRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "  \"\"\"\n",
        "  Loads all the data into training_tasks, eval_tasks and test_tasks\n",
        "  \"\"\"\n",
        "\n",
        "  ## get paths\n",
        "  GCS_PATH = \"gs://kds-d3cfb3d523ca35d2517017a78110126404d01fdea69417ce49950459\"\n",
        "  training_filenames = tf.io.gfile.glob(GCS_PATH + \"/training/*\")\n",
        "  test_filenames = tf.io.gfile.glob(GCS_PATH + \"/test/*\")\n",
        "  eval_filenames = tf.io.gfile.glob(GCS_PATH + \"/evaluation/*\")\n",
        "\n",
        "  # create datasets with filenames\n",
        "  training_dataset = tf.data.Dataset.list_files(training_filenames)\n",
        "  eval_dataset = tf.data.Dataset.list_files(eval_filenames)\n",
        "  test_dataset = tf.data.Dataset.list_files(test_filenames)\n",
        "\n",
        "  # load the jsons\n",
        "  def load_task(filename):\n",
        "    task_json = tf.io.read_file(filename)\n",
        "    return task_json\n",
        "\n",
        "  training_dataset = training_dataset.map(load_task)\n",
        "  eval_dataset = eval_dataset.map(load_task)\n",
        "  test_dataset = test_dataset.map(load_task)\n",
        "\n",
        "  training_dataset_numpy = tf.data.Dataset.as_numpy_iterator(training_dataset) # convert to numpy iterator\n",
        "  eval_dataset_numpy = tf.data.Dataset.as_numpy_iterator(eval_dataset)\n",
        "  test_dataset_numpy = tf.data.Dataset.as_numpy_iterator(test_dataset)\n",
        "\n",
        "  ## create a numpy array of tasks (n_tasks, )\n",
        "  def list_from_jsons(jsons_numpy_iterator):\n",
        "    \"\"\"\n",
        "      Create a list of task dictionaries from jsons numpy interator\n",
        "    \"\"\"\n",
        "\n",
        "    tasks = []\n",
        "    for task in jsons_numpy_iterator:\n",
        "      tasks.append(json.loads(task))\n",
        "\n",
        "    return tasks\n",
        "\n",
        "  ## get numpy arrays of datasets\n",
        "  training_tasks = list_from_jsons(training_dataset_numpy)\n",
        "  eval_tasks = list_from_jsons(eval_dataset_numpy)\n",
        "  test_tasks = list_from_jsons(test_dataset_numpy)\n",
        "\n",
        "  return training_tasks, eval_tasks, test_tasks\n",
        "\n",
        "\n",
        "def load_data_from_jsons():\n",
        "  \"\"\"\n",
        "  Load tasks from jsons to lists of tasks.\n",
        "\n",
        "  Returns:\n",
        "  training_tasks, eval_tasks, test_tasks --> lists of tasks\n",
        "  \"\"\"\n",
        "\n",
        "  with open(\"training_tasks.json\", 'r') as f:\n",
        "    training_tasks = json.load(f)\n",
        "\n",
        "  with open(\"eval_tasks.json\", 'r') as f:\n",
        "    eval_tasks = json.load(f)\n",
        "  \n",
        "  with open(\"test_tasks.json\", 'r') as f:\n",
        "    test_tasks = json.load(f)\n",
        "\n",
        "  return training_tasks, eval_tasks, test_tasks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN8EaXLjB-yY",
        "colab_type": "text"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en8donwdCBMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_board(board, ax, title=\"\"):\n",
        "  \"\"\"\n",
        "  Plot a board on a given axis\n",
        "  \"\"\"\n",
        "  cmap = colors.ListedColormap(\n",
        "      ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
        "        '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
        "  norm = colors.Normalize(vmin=0, vmax=9)\n",
        "  \n",
        "  ax.imshow(board, cmap=cmap, norm=norm)\n",
        "  ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n",
        "  ax.set_yticks([x-0.5 for x in range(1+board.shape[0])])\n",
        "  ax.set_xticks([x-0.5 for x in range(1+board.shape[1])])     \n",
        "  ax.set_xticklabels([])\n",
        "  ax.set_yticklabels([])\n",
        "  ax.set_title(title)\n",
        "\n",
        "def plot_one(task, ax, i,train_or_test,input_or_output):\n",
        "  \"\"\"\n",
        "  Plot one task on a given axis\n",
        "  \"\"\"\n",
        "  cmap = colors.ListedColormap(\n",
        "      ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
        "        '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
        "  norm = colors.Normalize(vmin=0, vmax=9)\n",
        "  \n",
        "  input_matrix = task[train_or_test][i][input_or_output]\n",
        "  ax.imshow(input_matrix, cmap=cmap, norm=norm)\n",
        "  ax.grid(True,which='both',color='lightgrey', linewidth=0.5)    \n",
        "  ax.set_yticks([x-0.5 for x in range(1+len(input_matrix))])\n",
        "  ax.set_xticks([x-0.5 for x in range(1+len(input_matrix[0]))])     \n",
        "  ax.set_xticklabels([])\n",
        "  ax.set_yticklabels([])\n",
        "  ax.set_title(train_or_test + ' '+input_or_output)\n",
        "    \n",
        "\n",
        "def plot_task(task):\n",
        "    \"\"\"\n",
        "    Plots the first train and test pairs of a specified task,\n",
        "    using same color scheme as the ARC app\n",
        "    \"\"\"    \n",
        "    num_train = len(task['train'])\n",
        "    fig, axs = plt.subplots(2, num_train, figsize=(3*num_train,3*2))\n",
        "    for i in range(num_train):     \n",
        "        plot_one(task, axs[0,i],i,'train','input')\n",
        "        plot_one(task, axs[1,i],i,'train','output')        \n",
        "    plt.tight_layout()\n",
        "    plt.show()        \n",
        "        \n",
        "    num_test = len(task['test'])\n",
        "    fig, axs = plt.subplots(2, num_test, figsize=(3*num_test,3*2))\n",
        "    if num_test==1: \n",
        "        plot_one(task, axs[0],0,'test','input')\n",
        "        plot_one(task, axs[1],0,'test','output')     \n",
        "    else:\n",
        "        for i in range(num_test):      \n",
        "            plot_one(task, axs[0,i],i,'test','input')\n",
        "            plot_one(task, axs[1,i],i,'test','output')  \n",
        "    plt.tight_layout()\n",
        "    plt.show() \n",
        "  \n",
        "\n",
        "def plot_board_pairs(board_pairs, labels):\n",
        "  \"\"\"\n",
        "  Plots the board pairs (for siamese networks) with their label as a title\n",
        "  \"\"\"\n",
        "\n",
        "  fig, axs = plt.subplots(len(board_pairs), 2, figsize=(8, 3 * len(board_pairs)))\n",
        "  \n",
        "  for i, pair in enumerate(board_pairs):\n",
        "    # plot a pair on a given axis\n",
        "    plot_board(pair[0], axs[i, 0], title=\"anchor\") \n",
        "    plot_board(pair[1], axs[i, 1], title=labels[i])\n",
        "  \n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_decoder_boards(board_pairs):\n",
        "  \"\"\"\n",
        "  Plots the board pairs (for siamese networks) with their label as a title\n",
        "  \"\"\"\n",
        "\n",
        "  fig, axs = plt.subplots(len(board_pairs), 2, figsize=(8, 3 * len(board_pairs)))\n",
        "\n",
        "  for i, pair in enumerate(board_pairs):\n",
        "    # plot a pair on a given axis\n",
        "    plot_board(pair[0], axs[i, 0]) \n",
        "    plot_board(pair[1], axs[i, 1])\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def display_training_curves(hist, metric='accuracy', with_val=False):\n",
        "  \"\"\"display learning curves for keras history dict, args: history dict, with val --> boolean with/without val\"\"\"\n",
        "  plt.figure(figsize=(18,6))\n",
        "\n",
        "  # accuracy plots\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(hist[metric])\n",
        "  \n",
        "  if with_val:\n",
        "    plt.plot(hist['val_' + metric])\n",
        "    plt.legend(['Train', 'Validation'])\n",
        "  \n",
        "  else:\n",
        "    plt.legend(['Train'])\n",
        "  \n",
        "  plt.title('Model accuracy')\n",
        "  plt.xlabel('EPOCH')\n",
        "  plt.ylabel('Accuracy')\n",
        "\n",
        "  # loss plots\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(hist['loss'])\n",
        "\n",
        "  if with_val:\n",
        "    plt.plot(hist['val_loss'])\n",
        "    plt.legend(['Train loss', 'Val loss'])\n",
        "  \n",
        "  else:\n",
        "    plt.legend(['Train loss'])\n",
        "  \n",
        "  plt.title('Model loss')\n",
        "  plt.xlabel('EPOCH')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}